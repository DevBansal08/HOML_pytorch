{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f2fc8e",
   "metadata": {},
   "source": [
    "# <center>**Chapter 7 : Dimensionality Reduction**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65922a",
   "metadata": {},
   "source": [
    "- many ML probelms involve thousands or even millions of features for each training instance which makes it harder and extremely slow to find a good solution. This is called the curse of dimensionality.\n",
    "\n",
    "- **Warning :** reducing dimesionality can also drop some useful information just like compressing an image to JPEG can degerade its quality\n",
    "\n",
    "- apart from speeding up training and possibly improving our model's preformance , dimensionality reduction is also extremely useful in data visualisation. Reducing the number of dimensions down to two or three makes it possible to plot a condensed view of a high dimensional training set on a graph and often gain some important insights by visually detecting patterns such as clusters\n",
    "\n",
    "- in this chapter we'll go through three of the most popular dimensionality reductionn techniques:\n",
    "    1. PCA\n",
    "    2. random projection\n",
    "    3. local linear embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe3b81",
   "metadata": {},
   "source": [
    "## <center>**The curse of Dimensionality**</center>\n",
    "\n",
    "high dimensional datasets are often very sparse : most training instances are likely to be far away from each other, so training methods based on distance or similarity such as k nearest neighbours will be much less effective and some types of models will not be usable at all because they scale poorly with the dataset's dimensionality ( eg SVM or dense neural networks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e098d",
   "metadata": {},
   "source": [
    "## <center>**Main Approaches of Dimensionality Reduction**</center>\n",
    "\n",
    "**The two main approaches of reducing dimensionality**\n",
    "- Projection\n",
    "- Mainfold Learning\n",
    "\n",
    "### 1. **Projection**\n",
    "In most real world problems , training instances are not spread out uniformly across all dimesions. Many features are constant while others are highly correlated. As a result all training instances lie within a much lower dimensional subspace of the high dimensional space.\n",
    "We are essentially taking a high dimensional data and flattening it onto a lower dimensional space using linear transformations.\n",
    "\n",
    "### 2. **Mainfold Learning**\n",
    "ALthough projection is fast and often works well, its not always the best approch to reduce dimensionality reduction. In many cases the subspaces may twist and turn.\n",
    "Mainfold learning is a non linear  dimensionality reduction technique that assumes data lies on a lower dimensional mainfold embedded within a higher dimensional space, and seeks to discover and preserve that mainfold's structure when reducing dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d291ff1f",
   "metadata": {},
   "source": [
    "## <center>**Principal Component Analysis**</center>\n",
    "PCA is a process of figuring out most important features or principal components that has the most impact on the target varible\n",
    "\n",
    "**Note : Scale features before applying PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724aaf4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '\"c:/Users/DEV BANSAL/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98daefeb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
